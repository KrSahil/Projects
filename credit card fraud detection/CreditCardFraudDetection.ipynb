{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display top 5 and last 5 Rows of the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of Our DataSet (Number of rows and number of Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows 284807\n",
      "Number of columns 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Rows\",data.shape[0])\n",
    "print(\"Number of columns\",data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information About our dataset\n",
    "(Total number of rows, columns, data type of each column and memory requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Null Values in The Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in our data sets all the values are in the same range except the amount column.\n",
    "#so we are going to use standard scaler for feature scaling our amount column (only for amount column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#data['Amount'] = sc.fit_transform(data['Amount'])\n",
    "#this will give us error\n",
    "data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here time column can be external deciding factor but in our modelling process we can drop it \n",
    "data = data.drop(['Time'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicate values\n",
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the output is true so our data set contains some duplicate values\n",
    "# so lets drop some duplicated values\n",
    "data = data.drop_duplicates() # data_duplicates is a function of pana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "284807-275663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not handling Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    99.828414\n",
      "1     0.171586\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Class'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the class distribution of the target count variable in percentage\n",
    "print((data.groupby('Class')['Class'].count()/data['Class'].count()) *100)\n",
    "((data.groupby('Class')['Class'].count()/data['Class'].count()) *100).plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Feature Matrix In X and Response(Target) in vector Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwe are going to store out feature matrix in X mens our independent variables in X\\nand our responser also called as the target variable or dependent variable in  vector Y\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns='Class', axis = 1) # axis = 1, represent column \n",
    "# drop class from data set and store it to x\n",
    "y = data['Class']\n",
    "\n",
    "'''\n",
    "we are going to store out feature matrix in X mens our independent variables in X\n",
    "and our responser also called as the target variable or dependent variable in  vector Y\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Data set into the training set And Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\nstratify = y\\nit means I want to stratify the data based on Y\\n\\nIf we dont mention this Y then, distribution of 0 and 1 can be very different in the training data and testning data\\nso when we do stratify , there will be evenly distributed two classes in both x_train and x_test\\n\\nrandom_state = 2\\nhow do u want to split your data \\nit helps in reproducing the same output\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size= 0.2, stratify = y, random_state= 2)\n",
    "# x is feature and Y is class \n",
    "# test size = amoun of testing data you want\n",
    "# 0.2 means, 80 percent of the data goes to the training data and 20 percentage goes to the testing data \n",
    "# x_train = (30 column) features will be stored here for training (80%)\n",
    "# y_train = (1 coulum (class)) features will be stored here for training (80%)\n",
    "# x_test = (30 column) features will be stored here for testing (20%)\n",
    "\n",
    "'''  \n",
    "stratify = y\n",
    "it means I want to stratify the data based on Y\n",
    "\n",
    "If we dont mention this Y then, distribution of 0 and 1 can be very different in the training data and testning data\n",
    "so when we do stratify , there will be evenly distributed two classes in both x_train and x_test\n",
    "\n",
    "random_state = 2\n",
    "how do u want to split your data \n",
    "it helps in reproducing the same output\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "# OveerSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now our machine learnign model is succesfully trained on our training set\n",
    "\n",
    "#so now let's perform prediction\n",
    "y_pred1 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990386882629279"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see logistic regression is 99 % accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65359477124183"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can see here, compared to accuracy precision recall and f1 scores are very low \n",
    "# this is due to our imbalanced data set , and this is true for each and every models\n",
    "# so that is why we have to handle imbalnced data set \n",
    "\n",
    "#alwasy remeber it is very dangerous to only use accuracy as a metric on imbalanced data set\n",
    "# we have to check precision, f1 and recall score as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Imbalaced DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "# OveerSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' So, in undersampling we randomly delete rows from majority class\\nto match them with the minority class \\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' So, in undersampling we randomly delete rows from majority class\n",
    "to match them with the minority class \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = data[data['Class']==0]\n",
    "fraud = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_sample = legit.sample(n=473)\n",
    "#this will randomly select 473 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenation Two Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([legit_sample, fraud], axis = 0,ignore_index = True) #concat joins two data set\n",
    "# if we give axis = 0 , all the 492 values will be addrd row wise\n",
    "# if we give axis = 1 , all the 492 values will be added column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473\n",
       "1    473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.725710</td>\n",
       "      <td>-0.729910</td>\n",
       "      <td>0.379334</td>\n",
       "      <td>1.493311</td>\n",
       "      <td>-1.296117</td>\n",
       "      <td>-0.115756</td>\n",
       "      <td>-0.978918</td>\n",
       "      <td>0.176452</td>\n",
       "      <td>1.557847</td>\n",
       "      <td>0.124048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299290</td>\n",
       "      <td>0.808934</td>\n",
       "      <td>0.127149</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>-0.376895</td>\n",
       "      <td>-0.596260</td>\n",
       "      <td>0.072504</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>0.046579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.060430</td>\n",
       "      <td>0.272341</td>\n",
       "      <td>1.655297</td>\n",
       "      <td>2.732467</td>\n",
       "      <td>-0.709159</td>\n",
       "      <td>0.444058</td>\n",
       "      <td>-0.578169</td>\n",
       "      <td>0.239697</td>\n",
       "      <td>-0.025472</td>\n",
       "      <td>0.427824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029028</td>\n",
       "      <td>0.140797</td>\n",
       "      <td>0.106545</td>\n",
       "      <td>0.408924</td>\n",
       "      <td>0.205685</td>\n",
       "      <td>-0.035969</td>\n",
       "      <td>0.064699</td>\n",
       "      <td>0.037070</td>\n",
       "      <td>-0.353229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.134977</td>\n",
       "      <td>0.955244</td>\n",
       "      <td>0.361034</td>\n",
       "      <td>-0.660313</td>\n",
       "      <td>0.817873</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>0.977475</td>\n",
       "      <td>-0.295500</td>\n",
       "      <td>1.366566</td>\n",
       "      <td>-0.095910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.459570</td>\n",
       "      <td>-0.692877</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>-0.471186</td>\n",
       "      <td>-0.493522</td>\n",
       "      <td>0.084698</td>\n",
       "      <td>0.163491</td>\n",
       "      <td>-0.084521</td>\n",
       "      <td>-0.317566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.762107</td>\n",
       "      <td>-3.003754</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>0.404317</td>\n",
       "      <td>-3.863718</td>\n",
       "      <td>2.322592</td>\n",
       "      <td>3.125790</td>\n",
       "      <td>-0.298802</td>\n",
       "      <td>-1.318039</td>\n",
       "      <td>-0.222178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713553</td>\n",
       "      <td>0.587126</td>\n",
       "      <td>2.258683</td>\n",
       "      <td>-0.049891</td>\n",
       "      <td>0.110635</td>\n",
       "      <td>-0.097509</td>\n",
       "      <td>-0.334083</td>\n",
       "      <td>-0.020818</td>\n",
       "      <td>3.902134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.315114</td>\n",
       "      <td>-1.287705</td>\n",
       "      <td>1.064429</td>\n",
       "      <td>-1.395046</td>\n",
       "      <td>0.157567</td>\n",
       "      <td>-0.987610</td>\n",
       "      <td>0.323872</td>\n",
       "      <td>0.121464</td>\n",
       "      <td>1.323547</td>\n",
       "      <td>-1.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359889</td>\n",
       "      <td>0.596933</td>\n",
       "      <td>0.566206</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>-0.411720</td>\n",
       "      <td>-0.873336</td>\n",
       "      <td>0.144454</td>\n",
       "      <td>0.224660</td>\n",
       "      <td>0.426757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.725710 -0.729910  0.379334  1.493311 -1.296117 -0.115756 -0.978918   \n",
       "1  1.060430  0.272341  1.655297  2.732467 -0.709159  0.444058 -0.578169   \n",
       "2 -0.134977  0.955244  0.361034 -0.660313  0.817873 -0.474545  0.977475   \n",
       "3 -1.762107 -3.003754  0.970024  0.404317 -3.863718  2.322592  3.125790   \n",
       "4 -1.315114 -1.287705  1.064429 -1.395046  0.157567 -0.987610  0.323872   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.176452  1.557847  0.124048  ...  0.299290  0.808934  0.127149  0.005090   \n",
       "1  0.239697 -0.025472  0.427824  ... -0.029028  0.140797  0.106545  0.408924   \n",
       "2 -0.295500  1.366566 -0.095910  ... -0.459570 -0.692877  0.011372 -0.471186   \n",
       "3 -0.298802 -1.318039 -0.222178  ...  0.713553  0.587126  2.258683 -0.049891   \n",
       "4  0.121464  1.323547 -1.693256  ...  0.359889  0.596933  0.566206  0.044162   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0 -0.376895 -0.596260  0.072504 -0.001869  0.046579      0  \n",
       "1  0.205685 -0.035969  0.064699  0.037070 -0.353229      0  \n",
       "2 -0.493522  0.084698  0.163491 -0.084521 -0.317566      0  \n",
       "3  0.110635 -0.097509 -0.334083 -0.020818  3.902134      0  \n",
       "4 -0.411720 -0.873336  0.144454  0.224660  0.426757      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.087943</td>\n",
       "      <td>-0.068006</td>\n",
       "      <td>0.073765</td>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.056455</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>0.071311</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>-0.029823</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.020281</td>\n",
       "      <td>-0.005530</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>-0.006664</td>\n",
       "      <td>0.058451</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>0.055108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.498280</td>\n",
       "      <td>3.405965</td>\n",
       "      <td>-6.729599</td>\n",
       "      <td>4.472591</td>\n",
       "      <td>-2.957197</td>\n",
       "      <td>-1.432518</td>\n",
       "      <td>-5.175912</td>\n",
       "      <td>0.953255</td>\n",
       "      <td>-2.522124</td>\n",
       "      <td>-5.453274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405043</td>\n",
       "      <td>0.466550</td>\n",
       "      <td>0.086639</td>\n",
       "      <td>-0.096464</td>\n",
       "      <td>-0.106643</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.213774</td>\n",
       "      <td>0.078270</td>\n",
       "      <td>0.142021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "Class                                                                         \n",
       "0     -0.087943 -0.068006  0.073765  0.020142  0.056455  0.034463  0.071311   \n",
       "1     -4.498280  3.405965 -6.729599  4.472591 -2.957197 -1.432518 -5.175912   \n",
       "\n",
       "             V8        V9       V10  ...       V20       V21       V22  \\\n",
       "Class                                ...                                 \n",
       "0      0.010597 -0.029823  0.010723  ...  0.000563  0.020281 -0.005530   \n",
       "1      0.953255 -2.522124 -5.453274  ...  0.405043  0.466550  0.086639   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28    Amount  \n",
       "Class                                                                        \n",
       "0      0.008064  0.002234 -0.006664  0.058451  0.028188  0.016719  0.055108  \n",
       "1     -0.096464 -0.106643  0.040615  0.050456  0.213774  0.078270  0.142021  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.groupby('Class').mean()\n",
    "\n",
    "# the nature of the data set did not change . \n",
    "# we still have almost the same difference as above\n",
    "\n",
    "# this step is necessary to check if we got good sample or a bad sample\n",
    "# as we got similar value so the sample is good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into feature and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfeatures = v1,v2.....v28\\nTarget = class = 0 or 1\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "features = v1,v2.....v28\n",
    "Target = class = 0 or 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_dataset.drop(columns='Class', axis = 1) # axis = 1, represent column \n",
    "# drop class from data set and store it to x\n",
    "Y = new_dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0    1.725710 -0.729910  0.379334  1.493311 -1.296117 -0.115756 -0.978918   \n",
      "1    1.060430  0.272341  1.655297  2.732467 -0.709159  0.444058 -0.578169   \n",
      "2   -0.134977  0.955244  0.361034 -0.660313  0.817873 -0.474545  0.977475   \n",
      "3   -1.762107 -3.003754  0.970024  0.404317 -3.863718  2.322592  3.125790   \n",
      "4   -1.315114 -1.287705  1.064429 -1.395046  0.157567 -0.987610  0.323872   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "941 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494 -0.882850   \n",
      "942  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536 -1.413170   \n",
      "943 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346 -2.234739   \n",
      "944 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548 -2.208002   \n",
      "945  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695  0.223050   \n",
      "\n",
      "           V8        V9       V10  ...       V20       V21       V22  \\\n",
      "0    0.176452  1.557847  0.124048  ... -0.113524  0.299290  0.808934   \n",
      "1    0.239697 -0.025472  0.427824  ... -0.160179 -0.029028  0.140797   \n",
      "2   -0.295500  1.366566 -0.095910  ...  0.121478 -0.459570 -0.692877   \n",
      "3   -0.298802 -1.318039 -0.222178  ...  2.782870  0.713553  0.587126   \n",
      "4    0.121464  1.323547 -1.693256  ...  0.400206  0.359889  0.596933   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "941  0.697211 -2.064945 -5.587794  ...  1.252967  0.778584 -0.319189   \n",
      "942  0.248525 -1.127396 -3.232153  ...  0.226138  0.370612  0.028234   \n",
      "943  1.210158 -0.652250 -3.463891  ...  0.247968  0.751826  0.834108   \n",
      "944  1.058733 -1.632333 -5.245984  ...  0.306271  0.583276 -0.269209   \n",
      "945 -0.068384  0.577829 -0.888722  ... -0.017652 -0.164350 -0.295135   \n",
      "\n",
      "          V23       V24       V25       V26       V27       V28    Amount  \n",
      "0    0.127149  0.005090 -0.376895 -0.596260  0.072504 -0.001869  0.046579  \n",
      "1    0.106545  0.408924  0.205685 -0.035969  0.064699  0.037070 -0.353229  \n",
      "2    0.011372 -0.471186 -0.493522  0.084698  0.163491 -0.084521 -0.317566  \n",
      "3    2.258683 -0.049891  0.110635 -0.097509 -0.334083 -0.020818  3.902134  \n",
      "4    0.566206  0.044162 -0.411720 -0.873336  0.144454  0.224660  0.426757  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "941  0.639419 -0.294885  0.537503  0.788395  0.292680  0.147968  1.206024  \n",
      "942 -0.145640 -0.081049  0.521875  0.739467  0.389152  0.186637 -0.350191  \n",
      "943  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361 -0.041818  \n",
      "944 -0.456108 -0.183659 -0.328168  0.606116  0.884876 -0.253700  0.626302  \n",
      "945 -0.072173 -0.450261  0.313267 -0.289617  0.002988 -0.015309 -0.183191  \n",
      "\n",
      "[946 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "941    1\n",
      "942    1\n",
      "943    1\n",
      "944    1\n",
      "945    1\n",
      "Name: Class, Length: 946, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\nstratify = y\\nit means I want to stratify the data based on Y\\n\\nIf we dont mention this Y then, distribution of 0 and 1 can be very different in the training data and testning data\\nso when we do stratify , there will be evenly distributed two classes in both x_train and x_test\\n\\nrandom_state = 2\\nhow do u want to split your data \\nit helps in reproducing the same output\\n\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size= 0.2, stratify = Y, random_state= 2)\n",
    "# x is feature and Y is class \n",
    "# test size = amoun of testing data you want\n",
    "# 0.2 means, 80 percent of the data goes to the training data and 20 percentage goes to the testing data \n",
    "# x_train = (30 column) features will be stored here for training (80%)\n",
    "# y_train = (1 coulum (class)) features will be stored here for training (80%)\n",
    "# x_test = (30 column) features will be stored here for testing (20%)\n",
    "\n",
    "'''  \n",
    "stratify = y\n",
    "it means I want to stratify the data based on Y\n",
    "\n",
    "If we dont mention this Y then, distribution of 0 and 1 can be very different in the training data and testning data\n",
    "so when we do stratify , there will be evenly distributed two classes in both x_train and x_test\n",
    "\n",
    "random_state = 2\n",
    "how do u want to split your data \n",
    "it helps in reproducing the same output\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946, 29) (756, 29) (190, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421052631578948"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9405405405405406"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157894736842105"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here ,, we can see all the scores are giving more and less the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nRandom Oversampling: Randomly duplicate examples in the minority class.\\nRandom Undersampling: Randomly delete examples in the majority class.\\n\\nRandom oversampling involves randomly selecting examples from the minority class, with replacement,\\nand adding them to the training dataset. Random undersampling involves randomly selecting examples\\nfrom the majority class and deleting them from the training dataset.\\n\\nIn the random under-sampling, the majority class instances are discarded at random until \\na more balanced distribution is reached.\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Random Oversampling: Randomly duplicate examples in the minority class.\n",
    "Random Undersampling: Randomly delete examples in the majority class.\n",
    "\n",
    "Random oversampling involves randomly selecting examples from the minority class, with replacement,\n",
    "and adding them to the training dataset. Random undersampling involves randomly selecting examples\n",
    "from the majority class and deleting them from the training dataset.\n",
    "\n",
    "In the random under-sampling, the majority class instances are discarded at random until \n",
    "a more balanced distribution is reached.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nDecision Trees bisect the space into smaller and smaller regions, \\nwhereas Logistic Regression fits a single line to divide the space exactly into two\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Decision Trees bisect the space into smaller and smaller regions, \n",
    "whereas Logistic Regression fits a single line to divide the space exactly into two\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#creating instance of Distacne tree Classifier\n",
    "\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's train decison tree classifier on our training set after undersampling\n",
    "dt.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets perform prediciton using this decison tree  classifier on our unseen sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157894736842105"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340659340659341"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913978494623656"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training our random forest classifier on our training set after undersampling\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing prediction\n",
    "y_pred4 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421052631578948"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we have to pass actual values and predicted values\n",
    "accuracy_score(Y_test,y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772727272727273"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_test,y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052631578947369"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_test,y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398907103825138"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test,y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\npassing model as a key\\n\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.DataFrame({'Models':['LR','DT','RF'],\n",
    "                            \"ACC\":[accuracy_score(Y_test,y_pred2)*100,\n",
    "                                   accuracy_score(Y_test,y_pred3)*100,\n",
    "                                   accuracy_score(Y_test,y_pred4)*100              \n",
    "                          ]})\n",
    "''' \n",
    "passing model as a key\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>94.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>91.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>94.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Models        ACC\n",
       "0     LR  94.210526\n",
       "1     DT  91.578947\n",
       "2     RF  94.210526"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = 'Models', y = 'ACC', data = final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Disadvantage of undersampling is we loose lot's of data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nOvercoming Class Imbalance using SMOTE Techniques\\nSMOTE: Synthetic Minority Oversampling Technique\\n\\nSMOTE is an oversampling technique where the synthetic samples are \\ngenerated for the minority class. This algorithm helps to overcome \\nthe overfitting problem posed by random oversampling.\\n\\n//yt - it is one of the most commonly used oversampling methods to solve\\ndata imbalance problem, \\n\\nwe are not generating dublicates rather synthectic data points\\n\\n\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Overcoming Class Imbalance using SMOTE Techniques\n",
    "SMOTE: Synthetic Minority Oversampling Technique\n",
    "\n",
    "SMOTE is an oversampling technique where the synthetic samples are \n",
    "generated for the minority class. This algorithm helps to overcome \n",
    "the overfitting problem posed by random oversampling.\n",
    "\n",
    "//yt - it is one of the most commonly used oversampling methods to solve\n",
    "data imbalance problem, \n",
    "\n",
    "we are not generating dublicates rather synthectic data points\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # we start everything from the befining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data2['Amount'] = sc.fit_transform(pd.DataFrame(data2['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.drop(['Time'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2.drop(columns='Class', axis = 1) # axis = 1, represent column \n",
    "# drop class from data set and store it to x\n",
    "y = data2['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing smote\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res,y_res = SMOTE().fit_resample(X,y) # passing independent varaible and dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550380,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are having same no of samples in legit and fraudlent transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res, test_size= 0.2, random_state= 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444020494930775"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729300903620286"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141683180917405"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9426343219226877"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982012427777173"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974945988634919"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982013734966025"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989091504099776"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999918238308078"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999181929736854"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998363993310551"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame({'Models':['LR','DT','RF'],\n",
    "                            \"ACC\":[accuracy_score(y_test,y_pred5)*100,\n",
    "                                   accuracy_score(y_test,y_pred6)*100,\n",
    "                                   accuracy_score(y_test,y_pred7)*100              \n",
    "                          ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Models', ylabel='ACC'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = 'Models', y = 'ACC', data = final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nwe have used train test split just to evaluate the perforamnce of our machine learning\\nmodels. But for production we have to train our best model on entire data set.\\n\\nSo, here we are going to train our best model (random forest classifier) on entire data set\\nafter over soampling\\n\\nso for that let us create once again instance of our best model\\n\\n'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so that training again and again is not required\n",
    "''' \n",
    "we have used train test split just to evaluate the perforamnce of our machine learning\n",
    "models. But for production we have to train our best model on entire data set.\n",
    "\n",
    "So, here we are going to train our best model (random forest classifier) on entire data set\n",
    "after over soampling\n",
    "\n",
    "so for that let us create once again instance of our best model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nAter SMOTE our independent variables are available insed X_res and and our \\nindependent varaible class available inside y_res\\n\\nSo, we have to train our best model random forest classifier on these variablbes\\nmeans on independent varibales and dependent variables available insed x_res and y_res \\n'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try our best model on entire data set after oversampling\n",
    "\n",
    "''' \n",
    "Ater SMOTE our independent variables are available insed X_res and and our \n",
    "independent varaible class available inside y_res\n",
    "\n",
    "So, we have to train our best model random forest classifier on these variablbes\n",
    "means on independent varibales and dependent variables available insed x_res and y_res \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's save our best model random forest classifier\n",
    "# again and again training is not required and in future we cen perform prediction using this saved model\n",
    "# So for that we use Joblib library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now, let's save our model, so for that we have to use dump method of this joblib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Credit_Card_Model']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and here we have to pass instance of our best model \n",
    "joblib.dump(rf1,\"Credit_Card_Model\")\n",
    "#now our model is succesfully saved with this name\n",
    "# now in future we can perform prediciton using this saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the saved model\n",
    "model = joblib.load(\"Credit_Card_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legit Transcation\n"
     ]
    }
   ],
   "source": [
    "if pred == 0:\n",
    "    print(\"Legit Transcation\")\n",
    "else:\n",
    "    print(\"Fraudelent Transactioin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
